!! Scraping HTML

Internet pages provide a lot of information and often you would like to be able to access and manipulate it in another form than HTML: HTML is just plain verbose. What you would like is to get access to only the information you are interested in and get the results in a form that you can easily build more software. This is the objective of HTML scraping. In Pharo you can scrap web pages using different libraries such as XMLParser and SOUP. 
In this chappter we will show you how we can do that using XMLParser to scrap and JSON to collect information. 

This chapter has been originally written by Peter Kenny and we thank him for sharing with the community this little tutorial. 


!!! Getting started
You can use the Catalog browser to load XMLParserHTML and NeoJSON just execute the following expressions: 

[[[
Gofer it
   smalltalkhubUser: 'PharoExtras' project: 'XMLParserHTML';
   configurationOf: 'XMLParserHTML';
   loadStable.
]]]

[[[
Gofer it
   smalltalkhubUser: 'PharoExtras' project: 'XPath';
   configurationOf: 'XPath';
   loadStable.
]]]

[[[
Gofer it
   smalltalkhubUser: 'SvenVanCaekenberghe' project: 'Neo';
   configurationOf: 'NeoJSON';
   loadStable.
]]]


!!! Examples
Let us take for example the following site 
*https://ndb.nal.usda.gov/ndb/foods?format=&count=&max=100&sort=&fgcd=&manu=&lfacet=&qlookup=&offset=0&order=desc*.


+A possible source of information.>file://figures/food.png|width=100|label=fgmap+

Other web site such as the magic the gathering database can be also nice to scrap.
*http://gatherer.wizards.com/Pages/Search/Default.aspx?set=[%22Amonkhet%22]*

!!! First cut 
Let us start. First read in the table of ingredients (first 100 rows only) as in the url. 
We use the HTML parser to convert text into an XML tree (a tree whose nodes are XML objects).

[[[
| ingredientsXML |
ingredientsXML := XMLHTMLParser parseURL: 'https://ndb.nal.usda.gov/ndb/foods?format=&count=&max=100&sort=&fgcd=&manu=&lfacet=&qlookup=&offset=0&order=desc'.
ingredientsXML inspect
]]]

You can execute the expression and inspect its result. You will obtain an inspector on the tree and you can navigate this tree as shown in Figure *@inspector*. 

+Navigating the XML document inside the inspector.>file://figures/InspectorXML.png|width=100|label=inspector+

Since you may want to work on files that you saved on your disc you can also parse a files and get an XML tree as follows:

[[[
| ingredientsXML |
ingredientsXML := (XMLHTMLParser onFileNamed: 'FoodsList.html') parseDocument.
]]]



!!! Going back to our problem
"First read in the table of ingredients (first 100 rows only) as in the spec"

[[[
ingredientsXML := XMLHTMLParser parseURL: 'https://ndb.nal.usda.gov/ndb/search/list?format=&count=&max=50&sort=fd_s&fgcd=&manu=&lfacet=&qlookup=&ds=Standard+Reference&qt=&qp=&qa=&qn=&q=&ing=&offset=0&order=asc'.
]]]

"The detail rows are in the body of the table in the div node whose class is 'wbox'"

[[[
ingredientRows :=(ingredientsXML xPath: '//div[@class=''wbox'']//tbody/tr').
]]]
 
"Extract the text content of the four cells in each row"
[[[
ingredientCells := ingredientRows collect: 
               [:row| (row xPath: 'td') collect: 
                              [ :cell| cell  contentString trim]].
]]]

"To prepare for export to JSON, it is handy to put the three required fields (ignoring the first) in a Dictionary indexed by their field names"

[[[
ingredientsJSON := ingredientCells collect: 
               [ :row| { 'nbd_no' -> (row at: 2). 
                              'full-name' -> (row at: 3). 
                              'food-group' -> (row at: 4)} 
asOrderedDictionary ].
]]]
 
"If we 'do it and go' this line, we can see the JSON layout. In this demo, I have not bothered with exporting to a JSON file; it is easier to look at it in a Playground"

[[[
NeoJSONWriter toStringPretty: ingredientsJSON first.
]]]

"We can find the address of the ingredient details from the href in the second cell"
[[[
ingredientAddress := ingredientRows collect: 
               [ :row| (row xPath:'td[2]/a/@href') first value copyUpTo: $?].
]]]

"To show how to process the ingredient details, I have just processed the first ingredient in the file. The production version would have to run through all the rows in the ingredientAddress collection. We read and parse the detail file."

[[[
ingredientDetailsXML := XMLHTMLParser parseURL: 'https://ndb.nal.usda.gov', ingredientAddress first, '?format=Full'.
]]]


Finally assemble all the information for the first ingredient as a JSON file. NeoJSON automatically takes care of embedding dictionaries within a collection within a dictionary.

[[[
NeoJSONWriter toStringPretty: 
	((ingredientsJSON first) 
		at: 'factors' put: factorsJSON; 
		at: 'nutrients' put: nutrientJSON; 
		yourself).
]]]

!!! Conclusion 

We presented a way to extract information from structured document. The 